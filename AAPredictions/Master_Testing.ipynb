{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which Leagues?\n",
      "(all -> All the Leagues || done -> No more Leagues)\n",
      "['Premier_League', 'Bundesliga', 'Ligue_1', 'La_Liga', 'Serie_A', 'Eredivisie', 'Premiership']\n",
      "--------->Ligue_1\n",
      "['Premier_League', 'Bundesliga', 'Ligue_1', 'La_Liga', 'Serie_A', 'Eredivisie', 'Premiership']\n",
      "--------->done\n",
      "['Ligue_1'] L\n",
      "Make Predictions?\n",
      "0(No) / 1(Yes) :  1\n",
      "Here\n",
      "Ler novos ficheiros? Sim(1) Não(0) 0\n",
      "Antes de começar, por favor fechar todos os ficheiros Excel\n",
      "Estão fechados? Sim(1) Não(0) 1\n",
      "Betano in 0.01 seconds\n",
      "Here3\n",
      "Portal\n",
      "Portal9.csv\n",
      "Skyyyyyyyyyyyyyyyyyyyyyyyyyyyy\n",
      "Sky in 0.02 seconds\n",
      "Undeeeeeeeeeeeer\n",
      "Under in 0.01 seconds\n",
      "Which season?:   2021\n",
      "Prepare_Df só funciona com as datas já em formato YYYY-mm-dd, e em ligas \"normais\"\n",
      "Prepare_Df só funciona com as datas já em formato YYYY-mm-dd, e em ligas \"normais\"\n",
      "Prepare_Df só funciona com as datas já em formato YYYY-mm-dd, e em ligas \"normais\"\n",
      "Prepare_Df só funciona com as datas já em formato YYYY-mm-dd, e em ligas \"normais\"\n",
      "What\n",
      "sky 60 under 60\n",
      "0 of  60\n",
      "s 0\n",
      "1 of  60\n",
      "s 2\n",
      "2 of  60\n",
      "s 1\n",
      "3 of  60\n",
      "s 6\n",
      "4 of  60\n",
      "s 3\n",
      "5 of  60\n",
      "s 5\n",
      "6 of  60\n",
      "s 4\n",
      "7 of  60\n",
      "s 7\n",
      "8 of  60\n",
      "s 8\n",
      "9 of  60\n",
      "s 9\n",
      "10 of  60\n",
      "s 11\n",
      "11 of  60\n",
      "s 15\n",
      "12 of  60\n",
      "s 10\n",
      "13 of  60\n",
      "s 13\n",
      "14 of  60\n",
      "s 12\n",
      "15 of  60\n",
      "s 14\n",
      "16 of  60\n",
      "s 16\n",
      "17 of  60\n",
      "s 17\n",
      "18 of  60\n",
      "s 19\n",
      "19 of  60\n",
      "s 18\n",
      "20 of  60\n",
      "s 21\n",
      "21 of  60\n",
      "s 20\n",
      "22 of  60\n",
      "s 26\n",
      "23 of  60\n",
      "s 24\n",
      "24 of  60\n",
      "s 23\n",
      "25 of  60\n",
      "s 25\n",
      "26 of  60\n",
      "s 22\n",
      "27 of  60\n",
      "s 27\n",
      "28 of  60\n",
      "s 28\n",
      "29 of  60\n",
      "s 29\n",
      "30 of  60\n",
      "s 30\n",
      "31 of  60\n",
      "s 32\n",
      "32 of  60\n",
      "s 31\n",
      "33 of  60\n",
      "s 34\n",
      "34 of  60\n",
      "s 39\n",
      "35 of  60\n",
      "s 38\n",
      "36 of  60\n",
      "s 33\n",
      "37 of  60\n",
      "s 37\n",
      "38 of  60\n",
      "s 36\n",
      "39 of  60\n",
      "s 35\n",
      "40 of  60\n",
      "s 40\n",
      "41 of  60\n",
      "s 41\n",
      "42 of  60\n",
      "s 42\n",
      "43 of  60\n",
      "s 49\n",
      "44 of  60\n",
      "s 43\n",
      "45 of  60\n",
      "s 44\n",
      "46 of  60\n",
      "s 48\n",
      "47 of  60\n",
      "s 46\n",
      "48 of  60\n",
      "s 45\n",
      "49 of  60\n",
      "s 47\n",
      "50 of  60\n",
      "s 50\n",
      "51 of  60\n",
      "s 52\n",
      "52 of  60\n",
      "s 51\n",
      "53 of  60\n",
      "s 56\n",
      "54 of  60\n",
      "s 59\n",
      "55 of  60\n",
      "s 58\n",
      "56 of  60\n",
      "s 53\n",
      "57 of  60\n",
      "s 57\n",
      "58 of  60\n",
      "s 54\n",
      "59 of  60\n",
      "s 55\n",
      "last here we go\n",
      "original_size: sky 60 | under 60\n",
      "no_find []\n",
      "file_size 60\n",
      "SKYyy ['Marseille', 'Lorient', 'Nimes', 'Strasbourg', 'Monaco', 'Paris Saint-Germain', 'Angers', 'Lyon', 'Montpellier', 'Nice', 'Bordeaux', 'RC Lens', 'Rennes', 'St Etienne', 'Nantes', 'Dijon', 'Metz', 'Brest', 'Lille', 'Reims']\n",
      "Under ['Marseille', 'Lorient', 'Lens', 'Nimes', 'Strasbourg', 'Monaco', 'Angers', 'Lyon', 'Montpellier', 'Nice', 'Bordeaux', 'Paris SG', 'Rennes', 'St Etienne', 'Nantes', 'Dijon', 'Metz', 'Brest', 'Lille', 'Reims']\n",
      "What\n",
      "What\n",
      "done extra\n",
      "done a\n",
      "done b\n",
      "done c\n",
      "done d\n",
      "done e\n",
      "done f\n",
      "done g\n",
      "done h\n",
      "done i\n",
      "done j\n",
      "done k\n",
      "done l\n",
      "done m\n",
      "done n\n",
      "done o\n",
      "done p\n",
      "done q\n",
      "done r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joaom\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cagou no None\n",
      "T50\n",
      "Which season?:   x\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    883\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 884\u001b[1;33m                 \u001b[0mident\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    885\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\jupyter_client\\session.py\u001b[0m in \u001b[0;36mrecv\u001b[1;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[0;32m    812\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 813\u001b[1;33m             \u001b[0mmsg_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    814\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\zmq\\sugar\\socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[1;34m(self, flags, copy, track)\u001b[0m\n\u001b[0;32m    474\u001b[0m         \"\"\"\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[0mparts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m         \u001b[1;31m# have first part already, only loop while more to receive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-04930e16e4d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[0mAll_Predix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAll_Predix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[0mAll_Predix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'All_Predix.xlsx'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m \u001b[0mNot_Add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnot_add\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-35a6e8d55882>\u001b[0m in \u001b[0;36mNot_Add\u001b[1;34m(na)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m#Pega no not_add e devolve o not add, mas com as horas do último jogo das duas equipas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m#(Ou seja), diz a que horas podemos fazer scrape para conseguir prever\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mseason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Which season?:   '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseason\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Season '\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseason\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m' não é válida'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    857\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0mpassword\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         )\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import openpyxl\n",
    "\n",
    "from Betano import *\n",
    "from Portal import *\n",
    "from Sky_Under import *\n",
    "\n",
    "#se der erro pode ser por estes dois\n",
    "from big_dix import *\n",
    "from Multi_DeForest_Husky_C import *\n",
    "\n",
    "import Add_HUSKY as H1\n",
    "import Add_HUSKY6 as H6\n",
    "import Add_SKY as S1\n",
    "\n",
    "time.sleep(0.5)\n",
    "#------------------------- E que comece o código\n",
    "#Get the dfs\n",
    "\n",
    "#Betano\n",
    "downloads = 'C://Users//joaom//Downloads//'\n",
    "desktop = 'C://Users//joaom//Desktop//WScrapy2//Sky//'\n",
    "\n",
    "print('Which Leagues?')\n",
    "print('(all -> All the Leagues || done -> No more Leagues)')\n",
    "leag_done=True\n",
    "leagues = []\n",
    "leagues1=['Premier_League','Bundesliga','Ligue_1','La_Liga','Serie_A','Eredivisie','Premiership']\n",
    "while leag_done:\n",
    "    if sum([i in leagues1 for i in leagues ])==len(leagues1):\n",
    "        leag_done=False\n",
    "    else:\n",
    "        print(leagues1)\n",
    "        time.sleep(0.2)\n",
    "        leagues_aux = input_string_aux(input('--------->'))\n",
    "        if (leagues_aux in leagues) or ((leagues_aux not in ['all','done']) and (leagues_aux not in leagues1)):\n",
    "            print('Argument not valid')\n",
    "        else:\n",
    "            if leagues_aux=='done':\n",
    "                leag_done=False\n",
    "            elif leagues_aux=='all':\n",
    "                leagues = leagues1\n",
    "            elif leagues_aux in leagues1:\n",
    "                leagues += [leagues_aux]\n",
    "            else:\n",
    "                raise Exception('Uknown error')\n",
    "\n",
    "print(leagues,'L')\n",
    "\n",
    "print('Make Predictions?')\n",
    "is_predictions = int(input('0(No) / 1(Yes) :  '))\n",
    "if is_predictions not in [0,1]:\n",
    "    raise Exception('Argument not valid')\n",
    "print('Here')\n",
    "\n",
    "\n",
    "read_done=True\n",
    "while read_done:\n",
    "    Read = input('Ler novos ficheiros? Sim(1) Não(0) ')\n",
    "    if Read not in ['0','1']:\n",
    "        print('Invalid Key')\n",
    "    else:\n",
    "        read_done=False\n",
    "        \n",
    "excel_closed = True\n",
    "while excel_closed:\n",
    "    print('Antes de começar, por favor fechar todos os ficheiros Excel')\n",
    "    confirm = int(input('Estão fechados? Sim(1) Não(0) '))\n",
    "    if confirm==1:\n",
    "        excel_closed=False\n",
    "\n",
    "if Read=='1':\n",
    "    B = list(map(lambda x: 'betano' in x,list(os.listdir(downloads))))\n",
    "    if sum(B)!=1: #True==1 || False==0\n",
    "        raise Exception('Erro na extração do Betano, Temos '+str(sum(B))+' ocorrências')\n",
    "    else:\n",
    "        Bet_ind=np.where(B)[0][0]\n",
    "        betano = pd.read_csv(downloads+os.listdir(downloads)[Bet_ind])\n",
    "    save_rawBetano(betano)\n",
    "    Betano_autofilter()\n",
    "\n",
    "    #Portal\n",
    "    P = list(map(lambda x: 'oddsportal' in x,list(os.listdir(downloads))))\n",
    "    if sum(P)!=1: #True==1 || False==0\n",
    "        raise Exception('Erro na extração do Portal, Temos '+str(sum(P))+' ocorrências')\n",
    "    else:\n",
    "        Portal_ind=np.where(P)[0][0]\n",
    "        portal = pd.read_csv(downloads+os.listdir(downloads)[Portal_ind])\n",
    "    save_rawPortal(portal)\n",
    "    Portal_autofilter()\n",
    "\n",
    "\n",
    "    #Under\n",
    "    U = list(map(lambda x: 'understats' in x,list(os.listdir(downloads))))\n",
    "    if sum(U)!=1: #True==1 || False==0\n",
    "        raise Exception('Erro na extração do Under, Temos '+str(sum(U))+' ocorrências')\n",
    "    else:\n",
    "        Under_ind=np.where(U)[0][0]\n",
    "        under = pd.read_csv(downloads+os.listdir(downloads)[Under_ind])\n",
    "    save_rawUnder(under)\n",
    "    Under_autofilter()\n",
    "\n",
    "\n",
    "    #Sky\n",
    "    SK1 = list(map(lambda x: 'skysports' in x,list(os.listdir(downloads))))\n",
    "    if sum(SK1)!=1:\n",
    "        S2 = list(map(lambda x: 'skygames' in x,list(os.listdir(desktop))))\n",
    "        if sum(S2)!=1:\n",
    "            raise Exception('Erro na extração do Sky, Ocorrências: '+str(sum(SK1))+' (Downloads) || '+str(sum(S2))+' (Desktop)')\n",
    "        else:\n",
    "            Sky_ind=np.where(S2)[0][0]\n",
    "            sky = pd.read_csv(desktop+os.listdir(desktop)[Sky_ind])\n",
    "    else:\n",
    "        Sky_ind=np.where(SK1)[0][0]\n",
    "        sky = pd.read_csv(downloads+os.listdir(downloads)[Sky_ind])\n",
    "    save_rawSky(sky)\n",
    "    Sky_autofilter()\n",
    "        \n",
    "\n",
    "#Filtering the dataaaaaa\n",
    "#Betano\n",
    "Bdir = 'C://Users//joaom//Documents//Projetos//PYTHON//Apostas//AAPredictions//BetanoOdds//Filtered_Data//' \n",
    "Bdir2 = 'C://Users//joaom//Documents//Projetos//PYTHON//Apostas//AAPredictions//BetanoOdds//Merged_Data//' \n",
    "b1 = time.perf_counter()\n",
    "if Read=='0':\n",
    "    if 'Master_DF_Betano.csv' in os.listdir(Bdir2):\n",
    "        betano1 = pd.read_csv(Bdir2 + 'Master_DF_Betano.csv')\n",
    "    else:\n",
    "        betano_dfs = list(map(lambda x:pd.read_csv(Bdir+x),list(os.listdir(Bdir))))\n",
    "        betano_dfs = pd.concat(betano_dfs,sort=False)\n",
    "        betano1 = Merge_Betano(betano_dfs)\n",
    "        betano1.to_csv(Bdir2+'Master_DF_Betano.csv')\n",
    "else:\n",
    "    betano_dfs = list(map(lambda x:pd.read_csv(Bdir+x),list(os.listdir(Bdir))))\n",
    "    betano_dfs = pd.concat(betano_dfs,sort=False)\n",
    "    betano1 = Merge_Betano(betano_dfs)\n",
    "    betano1.to_csv(Bdir2+'Master_DF_Betano.csv')\n",
    "    \n",
    "b2 = time.perf_counter()\n",
    "print(f'Betano in {round(b2-b1,2)} seconds')\n",
    "\n",
    "print('Here3')\n",
    "#Portal\n",
    "print('Portal')\n",
    "Pdir = 'C://Users//joaom//Documents//Projetos//PYTHON//Apostas//AAPredictions//Portal_Info//Filtered_Data//' #dps se calhar também podemos fazer merge\n",
    "portal_dfs = os.listdir(Pdir)\n",
    "print('Portal'+str(max(list(map(lambda x:get_int_str(x),portal_dfs))))+'.csv')\n",
    "portal0 = pd.read_csv(Pdir+'Portal'+str(max(list(map(lambda x:get_int_str(x),portal_dfs))))+'.csv')\n",
    "\n",
    "\n",
    "#Sky\n",
    "print('Skyyyyyyyyyyyyyyyyyyyyyyyyyyyy')\n",
    "Sdir = 'C://Users//joaom//Documents//Projetos//PYTHON//Apostas//AAPredictions//Sky_Info//Filtered_Data//'  #dps se calhar também podemos fazer merge\n",
    "Sdir2 = 'C://Users//joaom//Documents//Projetos//PYTHON//Apostas//AAPredictions//Sky_Info//Merged_Data//'\n",
    "s1 = time.perf_counter()\n",
    "if Read=='0':\n",
    "    if 'Master_DF_Sky.csv' in os.listdir(Sdir2):\n",
    "        sky1 = pd.read_csv(Sdir2 + 'Master_DF_Sky.csv')\n",
    "    else:\n",
    "        sky_dfs = list(map(lambda x:pd.read_csv(Sdir+x),list(os.listdir(Sdir))))\n",
    "        sky_dfs = pd.concat(sky_dfs,sort=False)\n",
    "        sky1 = merge_SU(sky_dfs)\n",
    "        sky1.to_csv(Sdir2+'Master_DF_Sky.csv')\n",
    "else:\n",
    "    sky_dfs = list(map(lambda x:pd.read_csv(Sdir+x),list(os.listdir(Sdir))))\n",
    "    sky_dfs = pd.concat(sky_dfs,sort=False)\n",
    "    sky1 = merge_SU(sky_dfs)\n",
    "    sky1.to_csv(Sdir2+'Master_DF_Sky.csv')\n",
    "s2 = time.perf_counter()\n",
    "print(f'Sky in {round(s2-s1,2)} seconds')\n",
    "\n",
    "#Under\n",
    "print('Undeeeeeeeeeeeer')\n",
    "Udir = 'C://Users//joaom//Documents//Projetos//PYTHON//Apostas//AAPredictions//Under_Info//Filtered_Data//'  #dps se calhar também podemos fazer merge\n",
    "Udir2 = 'C://Users//joaom//Documents//Projetos//PYTHON//Apostas//AAPredictions//Under_Info//Merged_Data//'\n",
    "u1 = time.perf_counter()\n",
    "if Read=='0':\n",
    "    if 'Master_DF_Under.csv' in os.listdir(Udir2):\n",
    "        under1 = pd.read_csv(Udir2 + 'Master_DF_Under.csv')\n",
    "    else:\n",
    "        under_dfs = list(map(lambda x:pd.read_csv(Udir+x),list(os.listdir(Udir))))\n",
    "        under_dfs = pd.concat(under_dfs,sort=False)\n",
    "        under1 = merge_SU(under_dfs)\n",
    "        under1.to_csv(Udir2+'Master_DF_Under.csv')\n",
    "else:\n",
    "    under_dfs = list(map(lambda x:pd.read_csv(Udir+x),list(os.listdir(Udir))))\n",
    "    under_dfs = pd.concat(under_dfs,sort=False)\n",
    "    under1 = merge_SU(under_dfs)\n",
    "    under1.to_csv(Udir2+'Master_DF_Under.csv')\n",
    "u2 = time.perf_counter()\n",
    "print(f'Under in {round(u2-u1,2)} seconds')\n",
    "\n",
    "\n",
    "\n",
    "#IT´s TIME !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "#leagues=leagues1\n",
    "#Fazer depois o código para os Russos!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "not_add = pd.DataFrame({}) #vai ajudar a dizer qnd é q temos de fazer scrape\n",
    "All_Predix = pd.DataFrame({})\n",
    "for l in leagues:\n",
    "    season = int(input('Which season?:   '))\n",
    "    if len(str(season))!=4:\n",
    "        raise Exception('Season '+str(season)+' não é válida')\n",
    "    \n",
    "    if l in ['Premier_League','Bundesliga','Ligue_1','La_Liga','Serie_A']:\n",
    "        sky2 = Prepare__Df(sky1,season,l)\n",
    "        under2 = Prepare__Df(under1,season,l)\n",
    "        portal2 = Prepare__Df(portal0,season,l)\n",
    "        betano2 =Prepare__Df(betano1,season,l)\n",
    "\n",
    "        husky,lixo0 = Merge_Sky_Under(sky2,under2)\n",
    "\n",
    "        lixo1,portal3 = Portal_utn(sky2,portal2,l)\n",
    "        lixo2,betano3 = Betano_utn(sky2,betano2,l)\n",
    "\n",
    "\n",
    "        portal_add,final_add,portal_not_add,portal_len = PortalAdd_Sky2(portal3,husky)\n",
    "\n",
    "        not_add = pd.concat([not_add,portal_not_add],sort=False)\n",
    "        husky0 = pd.concat([husky,portal_add],sort=False).sort_values(['Date','Time'],ascending=[True,True]).reset_index(drop=True)\n",
    "        PreHusky= Betano_addodds(husky0,betano3)\n",
    "        \n",
    "        PreFile = pd.concat([husky,final_add],sort=False).sort_values(['Date','Time'],ascending=[True,True]).reset_index(drop=True)\n",
    "        File = Betano_addodds(PreFile,betano3)\n",
    "    elif l in ['Eredivisie','Premiership']:\n",
    "        sky2 = Prepare__Df(sky1,season,l)\n",
    "        \n",
    "        portal2 = Prepare__Df(portal0,season,l)\n",
    "        betano2 =Prepare__Df(betano1,season,l)            \n",
    "        lixo1,portal3 = Portal_utn(sky2,portal2,l)\n",
    "        print('Portal is OK----------------')\n",
    "        lixo2,betano3 = Betano_utn(sky2,betano2,l)\n",
    "        portal_add,final_add,portal_not_add,portal_len = PortalAdd_Sky2(portal3,sky2)\n",
    "        not_add = pd.concat([not_add,portal_not_add],sort=False)\n",
    "        sky3 = pd.concat([sky2,portal_add],sort=False).sort_values(['Date','Time'],ascending=[True,True]).reset_index(drop=True)\n",
    "        \n",
    "        PreHusky= Betano_addodds(sky3,betano3)\n",
    "        PreFile = pd.concat([sky2,final_add],sort=False).sort_values(['Date','Time'],ascending=[True,True]).reset_index(drop=True)\n",
    "        File = Betano_addodds(PreFile,betano3)\n",
    "    if is_predictions==1:\n",
    "        if not(portal_add.empty):\n",
    "            Predix = Predix_League(PreHusky,l,portal_len)\n",
    "            All_Predix = pd.concat([All_Predix,Predix],sort=False)\n",
    "        #if l == 'Ligue_1': #o modelo e os valores limite estão errados\n",
    "        #    modelx = 'Husky_DFLL1_P2.pickle'\n",
    "        #    TL = 60\n",
    "        #    FL = 60\n",
    "        #    clubs = H1.findall_clubs2_new(PreHusky,read=False)\n",
    "        #    Husky0 = H1.join_husky(PreHusky,clubs,5,diff=False)\n",
    "        #    Husky = Husky0.tail(portal_len)\n",
    "        #    rd0=open('C://Users//joaom//Documents//Projetos//PYTHON//Apostas//ZModelos//'+modelx,'rb')\n",
    "        #    F=pickle.load(rd0)\n",
    "        #    lixo_Train=pickle.load(rd0)\n",
    "        #    lixo_Test=pickle.load(rd0)\n",
    "        #    T_df=pickle.load(rd0)\n",
    "        #    rd0.close()\n",
    "        #    print(Husky.columns)\n",
    "        #    big__ = Big_dix(Husky,F,T_df,var=1,tree_list=[TL],forest_list=[FL],optimize=False)\n",
    "        #    Predix = go_get(big__,mode=2,lista=['Tree_Forest','TL'+str(TL),'FL'+str(FL),'Predicted'])\n",
    "        #    Predix = Predix.drop(['Index','Tree Score %','Tree_var%'+str(TL),'ForestPredix_'+str(FL)+'%','ForestReal_'+str(FL)+'%','Won/NotWon'],axis=1)\n",
    "        #    betano_dfs2 = list(map(lambda x:pd.read_csv(Bdir+x),list(os.listdir(Bdir))))\n",
    "        #    Betano_TopOdds = Betano_oddtime(betano_dfs2,odd='ODDH',x=5,sort=True,league=l)\n",
    "        #    lixo2,Betano_TopOdds = Betano_utn(sky2,Betano_TopOdds,l)\n",
    "        #    Predix=Odds_Top(Predix,Betano_TopOdds)\n",
    "        \n",
    "        \n",
    "        # os valores dos thresholds dependem de modelo para mkdelo e cuidado q eles estão no drop clumns\n",
    "    League_Pref = {\n",
    "    'Premier_League':'PL','La_Liga':'LL','Ligue_1':'L','Serie_A':'SA','Bundesliga':'Bund','Eredivisie':'Ered',\n",
    "        'Premiership':'Scott'\n",
    "    }\n",
    "    File.to_excel('C://Users//joaom//Documents//Projetos//PYTHON//Apostas//AAPredictions//ADF//'+str(l)+'//New'+str(League_Pref[l])+str(str(season-1)[2:])+'_'+str(str(season)[2:])+'.xlsx',index=False)\n",
    "\n",
    "\n",
    "\n",
    "# FIM\n",
    "if is_predictions==1:\n",
    "    All_Predix = All_Predix.sort_values(['Date','Time'],ascending=[True,True]).reset_index(drop=True)\n",
    "    All_Predix.to_excel('All_Predix.xlsx',index=False)\n",
    "Not_Add(not_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Not_Add(na):\n",
    "    #Muito Importante!!!!!!!!!\n",
    "    #Pega no not_add e devolve o not add, mas com as horas do último jogo das duas equipas\n",
    "    #(Ou seja), diz a que horas podemos fazer scrape para conseguir prever\n",
    "    season = int(input('Which season?:   '))\n",
    "    if len(str(season))!=4:\n",
    "        raise Exception('Season '+str(season)+' não é válida')\n",
    "        \n",
    "    leagues = list(np.unique(na['League']))\n",
    "    League_Pref = {\n",
    "    'Premier_League':'PL','La_Liga':'LL','Ligue_1':'L','Serie_A':'SA','Bundesliga':'Bund','Eredivisie':'Ered',\n",
    "        'Premiership':'Scott'\n",
    "    }\n",
    "    Not_ADD = []\n",
    "    for l in leagues:\n",
    "        na2 = na.loc[na['League']==l]\n",
    "        file=pd.read_excel('C://Users//joaom//Documents//Projetos//PYTHON//Apostas//AAPredictions//ADF//'+str(l)+'//New'+str(League_Pref[l])+str(str(season-1)[2:])+'_'+str(str(season)[2:])+'.xlsx')\n",
    "        add_d=[]\n",
    "        add_t=[]\n",
    "        for i in range(len(na2)):\n",
    "            same=list(np.where(np.logical_and(na2.iloc[i]['HT']==file['HT'],na2.iloc[i]['AT']==file['AT']))[0])\n",
    "            if len(same)!=1:\n",
    "                raise Exception('WTF Error')\n",
    "                \n",
    "            \n",
    "            file2 = file[:(same[0])]\n",
    "            n=-1\n",
    "            date1,date2=0,0\n",
    "            done=False\n",
    "            doneD1 = True\n",
    "            doneD2 = True\n",
    "            while n>=(-len(file2)) and not(done):\n",
    "                if ((file2.iloc[n]['HT']==na2.iloc[i]['HT']) or (file2.iloc[n]['AT']==na2.iloc[i]['HT'])) and doneD1:\n",
    "                    doneD1=False\n",
    "                    date1 = [file2.iloc[n]['Date'],file2.iloc[n]['Time']+300] #passadas 2h o jogo já deve ter acabado\n",
    "                if ((file2.iloc[n]['AT']==na2.iloc[i]['AT']) or (file2.iloc[n]['HT']==na2.iloc[i]['AT'])) and doneD2:\n",
    "                    doneD2 = False\n",
    "                    date2 = [file2.iloc[n]['Date'],file2.iloc[n]['Time']+300] #passadas 2h o jogo já deve ter acabado\n",
    "                if (date1!=0) and (date2!=0):\n",
    "                    done = True\n",
    "                n=n-1\n",
    "            if not(done):\n",
    "                raise Exception('Game Not Found')\n",
    "            if date2[0]>date1[0]:\n",
    "                add_d += [date2[0]]\n",
    "                add_t += [date2[1]]\n",
    "            elif date2[0]==date1[0]:\n",
    "                if date2[1]>=date1[1]:\n",
    "                    add_d += [date2[0]]\n",
    "                    add_t += [date2[1]]\n",
    "                else:\n",
    "                    add_d += [date1[0]]\n",
    "                    add_t += [date1[1]]\n",
    "            else:\n",
    "                add_d += [date1[0]]\n",
    "                add_t += [date1[1]]\n",
    "            \n",
    "                \n",
    "        na2['Ready_ScrapeDate']=add_d\n",
    "        na2['Ready_ScrapeTime']=add_t\n",
    "        Not_ADD += [na2]\n",
    "        \n",
    "    Not_ADD = pd.concat(Not_ADD,sort=False)\n",
    "    return Not_ADD.sort_values(['Ready_ScrapeDate','Ready_ScrapeTime'],ascending=[True,True]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done extra\n",
      "done a\n",
      "done b\n",
      "done c\n",
      "done d\n",
      "done e\n",
      "done f\n",
      "done g\n",
      "done h\n",
      "done i\n",
      "done j\n",
      "done k\n",
      "done l\n",
      "done m\n",
      "done n\n",
      "done o\n",
      "done p\n",
      "done q\n",
      "done r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joaom\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cagou no None\n",
      "T70\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>League</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>HT</th>\n",
       "      <th>AT</th>\n",
       "      <th>Tree Score %</th>\n",
       "      <th>Tree_var%70</th>\n",
       "      <th>ForestPredix_25%</th>\n",
       "      <th>ForestReal_25%</th>\n",
       "      <th>Won/NotWon</th>\n",
       "      <th>ODDH_Aver.</th>\n",
       "      <th>ODDD_Aver.</th>\n",
       "      <th>ODDA_Aver.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Ligue_1</td>\n",
       "      <td>2020-10-02</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Paris Saint-Germain</td>\n",
       "      <td>Angers</td>\n",
       "      <td>61.77</td>\n",
       "      <td>41.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.08</td>\n",
       "      <td>9.75</td>\n",
       "      <td>21.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Ligue_1</td>\n",
       "      <td>2020-10-03</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>RC Lens</td>\n",
       "      <td>St Etienne</td>\n",
       "      <td>62.44</td>\n",
       "      <td>47.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.70</td>\n",
       "      <td>3.60</td>\n",
       "      <td>4.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Ligue_1</td>\n",
       "      <td>2020-10-04</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>Montpellier</td>\n",
       "      <td>Nimes</td>\n",
       "      <td>60.95</td>\n",
       "      <td>36.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.67</td>\n",
       "      <td>3.65</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>8.0</td>\n",
       "      <td>Ligue_1</td>\n",
       "      <td>2020-10-04</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>Rennes</td>\n",
       "      <td>Reims</td>\n",
       "      <td>60.12</td>\n",
       "      <td>38.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.63</td>\n",
       "      <td>3.60</td>\n",
       "      <td>5.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>9.0</td>\n",
       "      <td>Ligue_1</td>\n",
       "      <td>2020-10-04</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Lyon</td>\n",
       "      <td>Marseille</td>\n",
       "      <td>64.10</td>\n",
       "      <td>48.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.67</td>\n",
       "      <td>3.75</td>\n",
       "      <td>4.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Index   League       Date    Time                   HT          AT  \\\n",
       "50    0.0  Ligue_1 2020-10-02  2000.0  Paris Saint-Germain      Angers   \n",
       "51    1.0  Ligue_1 2020-10-03  1600.0              RC Lens  St Etienne   \n",
       "53    3.0  Ligue_1 2020-10-04  1200.0          Montpellier       Nimes   \n",
       "58    8.0  Ligue_1 2020-10-04  1600.0               Rennes       Reims   \n",
       "59    9.0  Ligue_1 2020-10-04  2000.0                 Lyon   Marseille   \n",
       "\n",
       "    Tree Score %  Tree_var%70  ForestPredix_25% ForestReal_25%  Won/NotWon  \\\n",
       "50         61.77        41.52               NaN            YES         1.0   \n",
       "51         62.44        47.08               NaN            YES         1.0   \n",
       "53         60.95        36.17               NaN             NO         0.0   \n",
       "58         60.12        38.85               NaN             NO         0.0   \n",
       "59         64.10        48.52               NaN             NO         0.0   \n",
       "\n",
       "    ODDH_Aver.  ODDD_Aver.  ODDA_Aver.  \n",
       "50        1.08        9.75       21.00  \n",
       "51        1.70        3.60        4.65  \n",
       "53        1.67        3.65        4.80  \n",
       "58        1.63        3.60        5.35  \n",
       "59        1.67        3.75        4.60  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Predix_League(PreHusky,l,portal_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predix_League(PreHusky,l,portal_len):\n",
    "    if l == 'Ligue_1': #o modelo e os valores limite estão errados\n",
    "        modelx = 'Husky_DFL1_P2.pickle'\n",
    "        TL = 70\n",
    "        FL = 24\n",
    "        clubs = H1.findall_clubs2_new(PreHusky,read=False)\n",
    "        Husky0 = H1.join_husky(PreHusky,clubs,5,diff=False)\n",
    "        Husky = Husky0.tail(portal_len)\n",
    "        rd0=open('C://Users//joaom//Documents//Projetos//PYTHON//Apostas//ZModelos//'+modelx,'rb')\n",
    "        F=pickle.load(rd0)\n",
    "        lixo_Train=pickle.load(rd0)\n",
    "        lixo_Test=pickle.load(rd0)\n",
    "        T_df=pickle.load(rd0)\n",
    "        rd0.close()\n",
    "        big__ = Big_dix(Husky,F,T_df,var=1,tree_list=[TL],forest_list=[FL],optimize=False)\n",
    "        Predix = go_get(big__,mode=2,lista=['Tree_Forest','TL'+str(TL),'FL'+str(FL),'Predicted'])\n",
    "        return Predix\n",
    "        Predix = Predix.drop(['Index','Tree Score %','Tree_var%'+str(TL),'ForestPredix_'+str(FL)+'%','ForestReal_'+str(FL)+'%','Won/NotWon'],axis=1)\n",
    "        betano_dfs2 = list(map(lambda x:pd.read_csv(Bdir+x),list(os.listdir(Bdir))))\n",
    "        Betano_TopOdds = Betano_oddtime(betano_dfs2,odd='ODDH',x=5,sort=True,league=l)\n",
    "        lixo2,Betano_TopOdds = Betano_utn(sky2,Betano_TopOdds,l)\n",
    "        Predix=Odds_Top(Predix,Betano_TopOdds)\n",
    "    elif l == 'Serie_A':\n",
    "        modelx = 'Husky6_DFSA1_P2_S.pickle'\n",
    "        TL = 57\n",
    "        FL = 46\n",
    "        clubs = H6.findall_clubs2_new(PreHusky,read=False)\n",
    "        Husky0 = H6.join_husky(PreHusky,clubs,5,diff=False)\n",
    "        Husky = Husky0.tail(portal_len)\n",
    "        rd0=open('C://Users//joaom//Documents//Projetos//PYTHON//Apostas//ZModelos//'+modelx,'rb')\n",
    "        F=pickle.load(rd0)\n",
    "        lixo_Train=pickle.load(rd0)\n",
    "        lixo_Test=pickle.load(rd0)\n",
    "        T_df=pickle.load(rd0)\n",
    "        rd0.close()\n",
    "        print(Husky.columns)\n",
    "        big__ = Big_dix(Husky,F,T_df,var=1,tree_list=[TL],forest_list=[FL],optimize=False)\n",
    "        Predix = go_get(big__,mode=2,lista=['Tree_Forest','TL'+str(TL),'FL'+str(FL),'Predicted'])\n",
    "        Predix = Predix.drop(['Index','Tree Score %','Tree_var%'+str(TL),'ForestPredix_'+str(FL)+'%','ForestReal_'+str(FL)+'%','Won/NotWon'],axis=1)\n",
    "        betano_dfs2 = list(map(lambda x:pd.read_csv(Bdir+x),list(os.listdir(Bdir))))\n",
    "        Betano_TopOdds = Betano_oddtime(betano_dfs2,odd='ODDH',x=5,sort=True,league=l)\n",
    "        lixo2,Betano_TopOdds = Betano_utn(sky2,Betano_TopOdds,l)\n",
    "        Predix=Odds_Top(Predix,Betano_TopOdds)\n",
    "                        \n",
    "                        \n",
    "    elif l == 'Premier_League':\n",
    "        modelx = 'Husky_DFPL1_P2_S.pickle'\n",
    "        TL = 76\n",
    "        FL = 41\n",
    "        clubs = H1.findall_clubs2_new(PreHusky,read=False)\n",
    "        Husky0 = H1.join_husky(PreHusky,clubs,5,diff=False)\n",
    "        Husky = Husky0.tail(portal_len)\n",
    "        rd0=open('C://Users//joaom//Documents//Projetos//PYTHON//Apostas//ZModelos//'+modelx,'rb')\n",
    "        F=pickle.load(rd0)\n",
    "        lixo_Train=pickle.load(rd0)\n",
    "        lixo_Test=pickle.load(rd0)\n",
    "        T_df=pickle.load(rd0)\n",
    "        rd0.close()\n",
    "        print(Husky.columns)\n",
    "        big__ = Big_dix(Husky,F,T_df,var=1,tree_list=[TL],forest_list=[FL],optimize=False)\n",
    "        Predix = go_get(big__,mode=2,lista=['Tree_Forest','TL'+str(TL),'FL'+str(FL),'Predicted'])\n",
    "        Predix = Predix.drop(['Index','Tree Score %','Tree_var%'+str(TL),'ForestPredix_'+str(FL)+'%','ForestReal_'+str(FL)+'%','Won/NotWon'],axis=1)\n",
    "        betano_dfs2 = list(map(lambda x:pd.read_csv(Bdir+x),list(os.listdir(Bdir))))\n",
    "        Betano_TopOdds = Betano_oddtime(betano_dfs2,odd='ODDH',x=5,sort=True,league=l)\n",
    "        lixo2,Betano_TopOdds = Betano_utn(sky2,Betano_TopOdds,l)\n",
    "        Predix=Odds_Top(Predix,Betano_TopOdds)\n",
    "                        \n",
    "                        \n",
    "    elif l == 'Bundesliga':\n",
    "        modelx = 'Husky_DFBund1_P1.pickle'\n",
    "        TL = 92\n",
    "        FL = 7\n",
    "        clubs = H1.findall_clubs2_new(PreHusky,read=False)\n",
    "        Husky0 = H1.join_husky(PreHusky,clubs,5,diff=False)\n",
    "        Husky = Husky0.tail(portal_len)\n",
    "        rd0=open('C://Users//joaom//Documents//Projetos//PYTHON//Apostas//ZModelos//'+modelx,'rb')\n",
    "        F=pickle.load(rd0)\n",
    "        lixo_Train=pickle.load(rd0)\n",
    "        lixo_Test=pickle.load(rd0)\n",
    "        T_df=pickle.load(rd0)\n",
    "        rd0.close()\n",
    "        print(Husky.columns)\n",
    "        big__ = Big_dix(Husky,F,T_df,var=1,tree_list=[TL],forest_list=[FL],optimize=False)\n",
    "        Predix = go_get(big__,mode=2,lista=['Tree_Forest','TL'+str(TL),'FL'+str(FL),'Predicted'])\n",
    "        Predix = Predix.drop(['Index','Tree Score %','Tree_var%'+str(TL),'ForestPredix_'+str(FL)+'%','ForestReal_'+str(FL)+'%','Won/NotWon'],axis=1)\n",
    "        betano_dfs2 = list(map(lambda x:pd.read_csv(Bdir+x),list(os.listdir(Bdir))))\n",
    "        Betano_TopOdds = Betano_oddtime(betano_dfs2,odd='ODDH',x=5,sort=True,league=l)\n",
    "        lixo2,Betano_TopOdds = Betano_utn(sky2,Betano_TopOdds,l)\n",
    "        Predix=Odds_Top(Predix,Betano_TopOdds)\n",
    "                        \n",
    "                        \n",
    "    elif l == 'La_Liga':\n",
    "        modelx = 'Husky_DFLL1_P2_S.pickle'\n",
    "        TL = 95\n",
    "        FL = 6\n",
    "        clubs = H1.findall_clubs2_new(PreHusky,read=False)\n",
    "        Husky0 = H1.join_husky(PreHusky,clubs,5,diff=False)\n",
    "        Husky = Husky0.tail(portal_len)\n",
    "        rd0=open('C://Users//joaom//Documents//Projetos//PYTHON//Apostas//ZModelos//'+modelx,'rb')\n",
    "        F=pickle.load(rd0)\n",
    "        lixo_Train=pickle.load(rd0)\n",
    "        lixo_Test=pickle.load(rd0)\n",
    "        T_df=pickle.load(rd0)\n",
    "        rd0.close()\n",
    "        print(Husky.columns)\n",
    "        big__ = Big_dix(Husky,F,T_df,var=1,tree_list=[TL],forest_list=[FL],optimize=False)\n",
    "        Predix = go_get(big__,mode=2,lista=['Tree_Forest','TL'+str(TL),'FL'+str(FL),'Predicted'])\n",
    "        Predix = Predix.drop(['Index','Tree Score %','Tree_var%'+str(TL),'ForestPredix_'+str(FL)+'%','ForestReal_'+str(FL)+'%','Won/NotWon'],axis=1)\n",
    "        betano_dfs2 = list(map(lambda x:pd.read_csv(Bdir+x),list(os.listdir(Bdir))))\n",
    "        Betano_TopOdds = Betano_oddtime(betano_dfs2,odd='ODDH',x=5,sort=True,league=l)\n",
    "        lixo2,Betano_TopOdds = Betano_utn(sky2,Betano_TopOdds,l)\n",
    "        Predix=Odds_Top(Predix,Betano_TopOdds)\n",
    "                        \n",
    "                        \n",
    "    elif l == 'Eredivisie':\n",
    "        modelx = 'Sky_DFEred1_P2_S.pickle'\n",
    "        TL = 64\n",
    "        FL = 16\n",
    "        clubs = S1.findall_clubs2_new(PreHusky,read=False)\n",
    "        Husky0 = S1.join_husky(PreHusky,clubs,5,diff=False)\n",
    "        Husky = Husky0.tail(portal_len)\n",
    "        rd0=open('C://Users//joaom//Documents//Projetos//PYTHON//Apostas//ZModelos//'+modelx,'rb')\n",
    "        F=pickle.load(rd0)\n",
    "        lixo_Train=pickle.load(rd0)\n",
    "        lixo_Test=pickle.load(rd0)\n",
    "        T_df=pickle.load(rd0)\n",
    "        rd0.close()\n",
    "        print(Husky.columns)\n",
    "        big__ = Big_dix(Husky,F,T_df,var=1,tree_list=[TL],forest_list=[FL],optimize=False)\n",
    "        Predix = go_get(big__,mode=2,lista=['Tree_Forest','TL'+str(TL),'FL'+str(FL),'Predicted'])\n",
    "        Predix = Predix.drop(['Index','Tree Score %','Tree_var%'+str(TL),'ForestPredix_'+str(FL)+'%','ForestReal_'+str(FL)+'%','Won/NotWon'],axis=1)\n",
    "        betano_dfs2 = list(map(lambda x:pd.read_csv(Bdir+x),list(os.listdir(Bdir))))\n",
    "        Betano_TopOdds = Betano_oddtime(betano_dfs2,odd='ODDH',x=5,sort=True,league=l)\n",
    "        lixo2,Betano_TopOdds = Betano_utn(sky2,Betano_TopOdds,l)\n",
    "        Predix=Odds_Top(Predix,Betano_TopOdds)\n",
    "                        \n",
    "                        \n",
    "    elif l == 'Premiership':\n",
    "        modelx = 'Sky_DFScott1_P2_S.pickle'\n",
    "        TL = 56\n",
    "        FL = 31\n",
    "        clubs = S1.findall_clubs2_new(PreHusky,read=False)\n",
    "        Husky0 = S1.join_husky(PreHusky,clubs,5,diff=False)\n",
    "        Husky = Husky0.tail(portal_len)\n",
    "        rd0=open('C://Users//joaom//Documents//Projetos//PYTHON//Apostas//ZModelos//'+modelx,'rb')\n",
    "        F=pickle.load(rd0)\n",
    "        lixo_Train=pickle.load(rd0)\n",
    "        lixo_Test=pickle.load(rd0)\n",
    "        T_df=pickle.load(rd0)\n",
    "        rd0.close()\n",
    "        print(Husky.columns)\n",
    "        big__ = Big_dix(Husky,F,T_df,var=1,tree_list=[TL],forest_list=[FL],optimize=False)\n",
    "        Predix = go_get(big__,mode=2,lista=['Tree_Forest','TL'+str(TL),'FL'+str(FL),'Predicted'])\n",
    "        Predix = Predix.drop(['Index','Tree Score %','Tree_var%'+str(TL),'ForestPredix_'+str(FL)+'%','ForestReal_'+str(FL)+'%','Won/NotWon'],axis=1)\n",
    "        betano_dfs2 = list(map(lambda x:pd.read_csv(Bdir+x),list(os.listdir(Bdir))))\n",
    "        Betano_TopOdds = Betano_oddtime(betano_dfs2,odd='ODDH',x=5,sort=True,league=l)\n",
    "        lixo2,Betano_TopOdds = Betano_utn(sky2,Betano_TopOdds,l)\n",
    "        Predix=Odds_Top(Predix,Betano_TopOdds)\n",
    "    else:\n",
    "        print(l)\n",
    "        raise Exception('Check League names')\n",
    "    \n",
    "    return Predix\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Odds_Top2(predix,bto):\n",
    "    #junta à df dos jogos previstos(predix) a info sobre a evolução das odds(bto)\n",
    "    predix = predix.drop(['ODDH_Aver.','ODDH_Aver.','ODDH_Aver.'],axis=1)\n",
    "    predix = predix.sort_values(['Date','Time'],ascending=[True,True]).reset_index(drop=True)\n",
    "    bto = bto.sort_values(['Date','Time'],ascending=[True,True]).reset_index(drop=True)\n",
    "    i=0\n",
    "    add_df = pd.DataFrame({})\n",
    "    while i<len(predix):\n",
    "        same = list(np.where(np.logical_and(\n",
    "        np.logical_and(bto['HT']==predix.iloc[i]['HT'],bto['AT']==predix.iloc[i]['AT']),\n",
    "        np.array(list(map(lambda x,y:days_diff(x,y),list(bto['Date']),[predix.iloc[i]['Date']]*len(list(bto['Date'])))))<=10\n",
    "        ))[0])\n",
    "        if len(same)==1:\n",
    "            add_df = pd.concat([add_df,pd.DataFrame(bto.loc[same[0]]).T])\n",
    "            i+=1\n",
    "        else:\n",
    "            print(len(same))\n",
    "            raise Exception(':(, dont know what happened')\n",
    "    add_df.sort_values(['Date','Time'],ascending=[True,True]).reset_index(drop=True)\n",
    "    return add_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
