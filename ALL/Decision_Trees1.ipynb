{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision_Trees1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Este módulo usa pandas.Dataframe\n",
      "E está feito para apenas prever variáveis categóricas 0/1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "print('Este módulo usa pandas.Dataframe')\n",
    "print('E está feito para apenas prever variáveis categóricas 0/1')\n",
    "\n",
    "def var_values(df,column): #dá nos uma lista dos valores de uma variável \n",
    "    #Nota, cada variável está associada a uma coluna\n",
    "    coluna=list(df.iloc[:,column]) #transforma coluna em lista\n",
    "    q=[]\n",
    "    for val in coluna:\n",
    "        if val not in q:\n",
    "            q+=[val]\n",
    "    return q\n",
    "\n",
    "######################## Algoritmo de ordenação Mergesort\n",
    "def fusao(u,v):\n",
    "    res=[]\n",
    "    i=0\n",
    "    j=0\n",
    "    for k in range(len(u)+len(v)):\n",
    "        if i<len(u) and (j==len(v) or u[i]<v[j]):\n",
    "            res.append(u[i])\n",
    "            i=i+1\n",
    "        else:\n",
    "            res.append(v[j])\n",
    "            j=j+1\n",
    "    return res\n",
    "\n",
    "def mergesort(w):\n",
    "    if len(w)<2:\n",
    "        return w\n",
    "    else:\n",
    "        m=len(w)//2\n",
    "        w1=mergesort(w[:m])\n",
    "        w2=mergesort(w[m:])\n",
    "        return fusao(w1,w2)\n",
    "#  #  #  #   #   #  #   #   #  #  #  #  #   # ALGORITMO DE ORDENAÇÃO MERGESORT\n",
    "\n",
    "\n",
    "\n",
    "def is_numeric(x): #diz se x é número ou não\n",
    "    return (isinstance(x,int)) or (isinstance(x,float)) or (isinstance(x,np.int64)) or (isinstance(x,np.float64))\n",
    "\n",
    "#NOTAAA: Parece q os números do pandas estão em numpy.int64  ou numpy.float64\n",
    "\n",
    "\n",
    "def string_column(df,column):\n",
    "    #True se coluna constituída por strings\n",
    "    q=var_values(df,column)\n",
    "    l=len(q)\n",
    "    i=0\n",
    "    found=False\n",
    "    while i<l and not(found):\n",
    "        if not(isinstance(q[i],str)):\n",
    "            found=True\n",
    "        i+=1\n",
    "    return not(found)\n",
    "    \n",
    "\n",
    "def is_categorical(df,column): \n",
    "    #diz se uma coluna numérica é categórica (sim/não, 0/1) (True)\n",
    "    #ou se é variável contínua (False)\n",
    "    if not(string_column(df,column)):\n",
    "        return len(var_values(df,column))==2\n",
    "    else:\n",
    "        print('Esta coluna é de str, não mede esta função')\n",
    "        return 'Esta coluna é de str, não mede esta função'\n",
    "    \n",
    "    \n",
    "       \n",
    "def not_categorical_values(df,column):\n",
    "    #dá as médias dos valores adjacentes para fazer as perguntas\n",
    "    v1=mergesort(var_values(df,column)) #dá jeito ter estes valores ordenados\n",
    "    values=[]\n",
    "    for i in range(len(v1)-1):\n",
    "        values+=[((v1[i]+v1[i+1])/2)]\n",
    "    return values \n",
    " \n",
    "    \n",
    "    \n",
    "def depend_counts(df):\n",
    "    #devolve um dicionário com os valores da variável dependente e as vezes q aparecem\n",
    "    #NOTA, esta função assume q a variável depend está na última coluna da df\n",
    "    counts={}\n",
    "    coluna=list(df.iloc[:,-1])\n",
    "    for val in coluna:\n",
    "        if val not in counts:\n",
    "            counts[val]=0\n",
    "        counts[val]+=1\n",
    "    return counts\n",
    "\n",
    "class Question:\n",
    "    \n",
    "    def __init__(self,column,value1,value2=None,tipo=0):\n",
    "        self.column=column\n",
    "        self.value1=value1\n",
    "        self.value2=value2\n",
    "        self.tipo=tipo\n",
    "        \n",
    "    def match(self,example):\n",
    "        #verifica se o example dá True ou False à pergunta\n",
    "        #example é uma linha/amostra em pd.DataFrame\n",
    "        val=example.iloc[0][self.column] #como é uma linha, queremos 0\n",
    "        if is_numeric(val):\n",
    "            if self.tipo==0:\n",
    "                return val > self.value1\n",
    "            else:\n",
    "                return self.value1<= val <= self.value2\n",
    "#as perguntas tipo 1 podem dar muitoooooooo jeito\n",
    "        else:\n",
    "            #se for uma string, não dá para ser maior/menor q uma string\n",
    "            return val == self.value1\n",
    "        \n",
    "def partition(df, question):\n",
    "    #divide uma dataframe em valores que que acertam a pergunta e que erram\n",
    "    true_rows,false_rows=pd.DataFrame(),pd.DataFrame()\n",
    "    for i in range(len(df.index)):\n",
    "        l=pd.DataFrame(df.iloc[i,:]).T #linha/amostra em linha\n",
    "        if question.match(l):\n",
    "            true_rows=pd.concat([true_rows,l],sort=False)\n",
    "        else:\n",
    "            false_rows=pd.concat([false_rows,l],sort=False)\n",
    "    false_rows=false_rows.reset_index(drop=True)\n",
    "    true_rows=true_rows.reset_index(drop=True)\n",
    "    return true_rows,false_rows\n",
    "\n",
    "\n",
    "def gini(df):\n",
    "    impurity=1\n",
    "    counts=depend_counts(df)\n",
    "    for depend in counts:\n",
    "        impurity-=((counts[depend]/len(df.index))**2)\n",
    "    return impurity\n",
    "\n",
    "def info_gain(true,false,current_impurity):\n",
    "    #true/false são as df q resultam de fazer uma pergunta (definida previamente)\n",
    "    #current_impurity é o gini da df sem ser dividida por uma pergunta\n",
    "    p=(len(true)/(len(true)+len(false)))\n",
    "    return current_impurity - ((p*gini(true))+((1-p)*gini(false)))\n",
    "\n",
    "def best_column_question(df,column,perguntas=2): #de uma coluna devolve a melhor pergunta e o seu info_gain\n",
    "    current_impurity=gini(df)\n",
    "    best_gain=0\n",
    "    best_question=None\n",
    "    \n",
    "    if string_column(df,column):\n",
    "        #print('gone to string')\n",
    "        values = var_values(df,column)\n",
    "        for val in values:\n",
    "            q=Question(column,val)\n",
    "            t,f =partition(df,q)\n",
    "            #se a pergunta não divide os dados fazemos SKIP\n",
    "            if len(t) == 0 or len(f) == 0:\n",
    "                continue\n",
    "            gain = info_gain(t,f,current_impurity)\n",
    "            if gain >= best_gain:\n",
    "                best_gain, best_question = gain, q\n",
    "    else:\n",
    "        if is_categorical(df,column):\n",
    "            #print('gone to categorical')\n",
    "            values = var_values(df,column) \n",
    "            assert len(values)==2\n",
    "            value = (values[0]+values[1])/2\n",
    "            q=Question(column,value,tipo=0)\n",
    "            t,f =partition(df,q)\n",
    "            gain = info_gain(t,f,current_impurity)\n",
    "            if gain >= best_gain:\n",
    "                best_gain, best_question = gain, q\n",
    "        else:\n",
    "            #print('oh shit, here we go again, best_question')\n",
    "            values=not_categorical_values(df,column)\n",
    "            #print(values,'oh shit values')\n",
    "            for i in range(perguntas): #Faz ciclo dos tipos de perguntas (1 ou 2)\n",
    "                if i==0: #para perguntas tipo 0\n",
    "                    for val in values:\n",
    "                        q=Question(column,val,tipo=0)\n",
    "                        t,f =partition(df,q)\n",
    "                        #se a pergunta não divide os dados fazemos SKIP\n",
    "                        if len(t) == 0 or len(f) == 0:\n",
    "                            continue\n",
    "                        gain = info_gain(t,f,current_impurity)\n",
    "                        if gain >= best_gain:\n",
    "                            best_gain, best_question = gain, q\n",
    "                            \n",
    "                else: #para perguntas tipo 1\n",
    "                    for i1 in range(1,len(values)-2): #se i1 for para lá de values[-2], não rende (ver caderno)\n",
    "                        for i2 in range(i1+1,len(values)-1):\n",
    "                            q=Question(column,values[i1],values[i2],tipo=1)\n",
    "                            t,f =partition(df,q)\n",
    "                            #se a pergunta não divide os dados fazemos SKIP\n",
    "                            if len(t) == 0 or len(f) == 0:\n",
    "                                continue\n",
    "                            gain = info_gain(t,f,current_impurity)\n",
    "                            if gain >= best_gain:\n",
    "                                best_gain, best_question = gain, q\n",
    "    #print(best_question.value1,best_question.value2,best_question.tipo)\n",
    "    return best_question,best_gain\n",
    "\n",
    "#  #  #   #   #   #  # Função Best_Node (também serve para as Random Forests)\n",
    "def best_node(df,forest=False,auto=True,columns_percentage=50): #melhor pergunta de todas as colunas\n",
    "    columns=len(df.columns)\n",
    "    best_question=None\n",
    "    best_gain=0\n",
    "    if not(forest): #se não quisermos usar esta função para o modelo Random Forests\n",
    "        #print(columns-1,'columns, best_node')\n",
    "        for i in range(columns-1): #a última coluna é a var. dep. por isso não queremos saber a sua pergunta (xD)\n",
    "            #print(i,'column,best_node')\n",
    "            if len(var_values(df,i))==1:\n",
    "               # print('opa, afinal tava mal --------------------')\n",
    "                continue\n",
    "            q, gain=best_column_question(df,i)\n",
    "            if gain >= best_gain:\n",
    "                best_gain, best_question = gain, q\n",
    "        #print(best_question.column,best_question.value1,best_question.value2,best_question.tipo)\n",
    "        return best_question, best_gain\n",
    "    \n",
    "    else: # se quisermos usar esta função para o modelo Random_Forests\n",
    "        \n",
    "        if auto: #em modo automático usa a raíz quadrada das colunas\n",
    "            stop=round(np.sqrt(columns)) \n",
    "        else: #se não tiver em auto, escolhemos a percentagem de perguntas a analisar\n",
    "            stop=round((columns*(columns_percentage))/100)\n",
    "            \n",
    "        ind=[] #lista dos índices das colunas q vamos usar\n",
    "        i=0\n",
    "        done=False\n",
    "        while i<columns and not(done):\n",
    "            ind+=[random.randrange(columns)]      #este ciclo encontra as colunas aleatórias \n",
    "            if len(ind)==stop:                    # que vamos utilizar\n",
    "                done=True\n",
    "            i+=1\n",
    "        for n in ind:\n",
    "            q, gain=best_column_question(df,n)\n",
    "            if gain >= best_gain:\n",
    "                best_gain, best_question = gain, q\n",
    "        #print(best_question.column,best_question.value1,best_question.value2,best_question.tipo)\n",
    "        return best_question, best_gain\n",
    "        \n",
    "##  #  #  #   #  #   #   #  #   #   #   #   #   #   #   #   #   #   #  #  #  \n",
    "\n",
    "def proba(df):\n",
    "    #calcula a probabilidade dos valores de um dicionário (em percentagem, para evitar float errors)\n",
    "    #É necessário para as Leafs\n",
    "    ind=len(df.index)\n",
    "    dicti=depend_counts(df)\n",
    "    new={0:0,1:0}  # este módulo de3 decision trees está feito para var dep de 0/1 APENAS\n",
    "    for var in dicti:\n",
    "        prob=round(100*(dicti[var]/ind),1)\n",
    "        new[var]=prob\n",
    "    return new\n",
    "\n",
    "\n",
    "class Leaf:\n",
    "    \n",
    "    def __init__(self,df):\n",
    "        self.predictions=depend_counts(df)\n",
    "        self.probability=proba(df)\n",
    "        \n",
    "        \n",
    "    #Leaf é um dicionário com as var. dep e as vezes q aparecem\n",
    "    \n",
    "class Decision_Node:\n",
    "    def __init__(self,question,true_branch,false_branch):\n",
    "        self.question=question\n",
    "        self.true_branch=true_branch\n",
    "        self.false_branch=false_branch\n",
    "\n",
    "def build_tree(df,limit=None,forest=False,auto=True,columns_percentage=50,count=0):\n",
    "    #função recursiva que faz árvore (very nice)\n",
    "    #limit: 2^limit (2**limit) é o número de leafs máximas que queremos\n",
    "    #limit=None, significa que não tem número máximo e constrói a árvore sem limites\n",
    "    #count é um 'counter' necessário para fazer funcionar o limit\n",
    "    #mas como a função é recursiva, ele tem de ser carregado de recursão em recursão\n",
    "    #como argumento. Não modificar o count qnd chamamos a função é 0 e sempre será\n",
    "    \n",
    "    \n",
    "    if count==limit:\n",
    "        return Leaf(df)\n",
    "    q,gain=best_node(df,forest,auto,columns_percentage)\n",
    "    if gain == 0:\n",
    "        return Leaf(df)\n",
    "    t, f =partition(df, q)\n",
    "    count+=1\n",
    "    true_branch=build_tree(t,limit=limit,forest=forest,auto=auto,columns_percentage=columns_percentage,count=count)\n",
    "    false_branch=build_tree(f,limit=limit,forest=forest,auto=auto,columns_percentage=columns_percentage,count=count)\n",
    "    print('done')\n",
    "    return Decision_Node(q,true_branch,false_branch)\n",
    "\n",
    "\n",
    "def classify_row(df,node,probability=True):\n",
    "    #sevre para chegarmos as folhas\n",
    "    #só serve para uma linha/amostra de dados serve \n",
    "    if isinstance(node,Leaf):\n",
    "        if probability:\n",
    "            return node.probability\n",
    "        else:\n",
    "            return node.predictions\n",
    "    if node.question.match(df):\n",
    "        return classify_row(df,node.true_branch,probability)\n",
    "    else:\n",
    "        return classify_row(df,node.false_branch,probability)\n",
    "    \n",
    "def test_tree(df,tree,var=1,limite=60):\n",
    "    #testa uma árvore, sabendo que a var só é considerada 1 se probabilidade>=limite\n",
    "    #devolve uma lista com os valores q previu\n",
    "\n",
    "    limit=len(df.index)\n",
    "    predicted=[] #valores previstos vão estar em lista\n",
    "    for i in range(limit):\n",
    "        row=pd.DataFrame(df.iloc[i,:]).T\n",
    "        d_proba=classify_row(row,tree)\n",
    "        if d_proba[var]>=60:\n",
    "            predicted+=[var]\n",
    "        else:\n",
    "            predicted+=[1-var] #se var=0,1 e se var=1,0\n",
    "    return predicted\n",
    "\n",
    "#  #   #  #  #  #  #  #  # #  # FUNÇÕES PARA A CONFUSION MATRIX\n",
    "#m é a confusion matrix, ind é o indíce da variável que queremos testar\n",
    "#ind começa em 0\n",
    "def sensitivity(m,ind):\n",
    "    if not(len(m)==len(m[0])):\n",
    "        return 'Erro! A matriz tem ser ser quadrada'\n",
    "    print('O índice começa em 0')\n",
    "    x=m[ind][ind]\n",
    "    n=0\n",
    "    q=[]\n",
    "    while n<len(m):\n",
    "        if n==ind:\n",
    "            n+=1\n",
    "        else:\n",
    "            q+=[m[n][ind]]\n",
    "            n+=1\n",
    "    y=sum(q)\n",
    "    return round((x/(x+y))*100,2)\n",
    "\n",
    "def specificity(m,ind):\n",
    "    if not(len(m)==len(m[0])):\n",
    "        return 'Erro! A matriz tem ser ser quadrada'\n",
    "    print('O índice começa em 0')\n",
    "    n=0\n",
    "    q=[]\n",
    "    while n<len(m):\n",
    "        if n==ind:\n",
    "            n+=1\n",
    "        else:\n",
    "            q+=[m[ind][n]]\n",
    "            n+=1\n",
    "    x=sum(q)\n",
    "    f=[]\n",
    "    i=0\n",
    "    while i<len(m):\n",
    "        c=0\n",
    "        if i==ind:\n",
    "            i+=1\n",
    "        else:\n",
    "            while c<len(m):\n",
    "                if c==ind:\n",
    "                    c+=1\n",
    "                else:\n",
    "                    f+=[m[i][c]]\n",
    "                    c+=1\n",
    "            i+=1\n",
    "    y=sum(f)\n",
    "    #print(q,f)  #verifica se os valores q estamos a escolher são os certos\n",
    "    return round((y/(x+y))*100,2)\n",
    "\n",
    "#A percentagem de previsões corretas feitas pelo modelo\n",
    "#i é a linha da confusion matrix (o outcome que queremos ver a percentagem de previsões corretas)\n",
    "def pred_percent(m,i):\n",
    "    #print(m)\n",
    "    if not(len(m)==len(m[0])):\n",
    "        return 'Erro! A matriz tem ser ser quadrada'\n",
    "    #print('O índice começa em 0')\n",
    "    x=m[i][i]\n",
    "    soma=sum(m[i])\n",
    "    if soma==0:\n",
    "        return 'Não previu nada para esta variável'\n",
    "    else:\n",
    "        return round((x/soma)*100,2)\n",
    "\n",
    "## # # # # #  #  #  #   #   #  #   #   #  #  #  #  #  #  #  #  # #\n",
    " \n",
    "def cmat_tree(df,tree,var=1,limite=60):\n",
    "    y_real=list(df.iloc[:,-1]) #lembrar q a variável dep tem de estar na última coluna\n",
    "    y_predicted=test_tree(df,tree,var,limite)\n",
    "    cmat=np.array([[0,0],[0,0]])\n",
    "    for i in range(len(y_real)):\n",
    "        if y_real[i]==1 and y_predicted[i]==1:\n",
    "            cmat[0][0]+=1\n",
    "        elif y_real[i]==1 and y_predicted[i]==0:\n",
    "            cmat[1][0]+=1\n",
    "        elif y_real[i]==0 and y_predicted[i]==1:\n",
    "            cmat[0][1]+=1\n",
    "        elif y_real[i]==0 and y_predicted[i]==0:\n",
    "            cmat[1][1]+=1\n",
    "        else:\n",
    "            print('Erro na cmat_tree')\n",
    "            return 'Erro na cmat_tree'\n",
    "    return cmat, pred_percent(cmat,1-var)\n",
    "#Porquê '1-var'?\n",
    "#lembrar q o 2o parametro do pred_percent indica a posição da variável na matriz\n",
    "#como 1 está na posição 0 e 0 está na posição 1\n",
    "#a posição é gerada corretamente em função da variável (0/1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(df,limit=None,forest=False,auto=True,columns_percentage=50,count=0):\n",
    "    #função recursiva que faz árvore (very nice)\n",
    "    print(count,'count')\n",
    "    print(count, '==', limit, 'count==limit')\n",
    "    if count==limit:\n",
    "        print('going if count==limit')\n",
    "        return None\n",
    "    q,gain=best_node(df,forest,auto,columns_percentage)\n",
    "    if gain == 0:\n",
    "        return None\n",
    "    t, f =partition(df, q)\n",
    "    count+=1\n",
    "    print('going true')\n",
    "    true_branch=build_tree(t,limit=limit,count=count)\n",
    "    print('going false')\n",
    "    false_branch=build_tree(f,limit=limit,count=count)\n",
    "    return Decision_Node(q,true_branch,false_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_=pd.read_csv('titanic_train.csv')\n",
    "df_=df_.drop(['PassengerId','Name','SibSp','Parch','Ticket','Fare','Cabin','Embarked'],axis=1)\n",
    "survived=df_['Survived']\n",
    "df_=df_.drop(['Survived'],1)\n",
    "df_=pd.concat([df_,pd.DataFrame(survived)],sort=False,axis=1)\n",
    "df_=df_.dropna().reset_index(drop=True)\n",
    "df_1=df_.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "tree1=build_tree(df_1,limit=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Leaf at 0x12b3edd55c0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree1.true_branch.false_branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(t,Leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
